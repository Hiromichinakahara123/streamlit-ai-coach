import streamlit as st
import sqlite3
import pandas as pd
from datetime import datetime
from zoneinfo import ZoneInfo
import os
import re
import json
import io
import google.generativeai as genai

# ---------- File parsing ----------
import pypdf
from docx import Document
from pptx import Presentation

# ---------- Gemini ----------
import google.generativeai as genai


# =====================================================
# DB
# =====================================================

DB_FILE = "pk_study_log.db"

def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("""
        CREATE TABLE IF NOT EXISTS logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT,
            topic TEXT,
            is_correct INTEGER
        )
    """)
    conn.commit()
    conn.close()

def log_result(topic, is_correct):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()

    now_jst = datetime.now(ZoneInfo("Asia/Tokyo"))

    c.execute(
        "INSERT INTO logs (timestamp, topic, is_correct) VALUES (?, ?, ?)",
        (now_jst.strftime("%Y-%m-%d %H:%M:%S"), topic, int(is_correct))
    )

    conn.commit()
    conn.close()


def get_stats():
    conn = sqlite3.connect(DB_FILE)
    df = pd.read_sql("SELECT * FROM logs", conn)
    conn.close()
    return df


# =====================================================
# Gemini
# =====================================================

def configure_gemini():
    api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    genai.configure(api_key=api_key)
    return True


# =====================================================
# File extraction
# =====================================================

def extract_from_pdf(data):
    reader = pypdf.PdfReader(io.BytesIO(data))
    texts = []
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            texts.append(f"ã€ãƒšãƒ¼ã‚¸ {i+1}ã€‘\n{text}")
    return "\n\n".join(texts)

def extract_from_docx(data):
    doc = Document(io.BytesIO(data))
    texts = []
    for p in doc.paragraphs:
        if p.style.name.startswith("Heading"):
            texts.append(f"\n## {p.text}\n")
        else:
            texts.append(p.text)
    return "\n".join(texts)

def extract_from_xlsx(data):
    xl = pd.ExcelFile(io.BytesIO(data))
    texts = []
    for sheet in xl.sheet_names:
        df = xl.parse(sheet)
        texts.append(f"\n## ã‚·ãƒ¼ãƒˆ: {sheet}\n")
        texts.append(df.to_csv(index=False))
    return "\n".join(texts)

def extract_from_pptx(data):
    prs = Presentation(io.BytesIO(data))
    texts = []
    for i, slide in enumerate(prs.slides):
        texts.append(f"\n## ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1}\n")
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                texts.append(shape.text)
    return "\n".join(texts)

def extract_text(uploaded_file):
    data = uploaded_file.read()
    ext = uploaded_file.name.split(".")[-1].lower()

    if ext == "pdf":
        return extract_from_pdf(data)
    if ext == "docx":
        return extract_from_docx(data)
    if ext == "xlsx":
        return extract_from_xlsx(data)
    if ext == "pptx":
        return extract_from_pptx(data)

    raise ValueError("æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")


# =====================================================
# AI problem generation
# =====================================================

def safe_json_load(text: str):
    text = text.strip()
    if text.startswith("```"):
        text = re.sub(r"^```.*?\n", "", text)
        text = text.rstrip("`").strip()

    # æœ€åˆã® [ ã‹ã‚‰æœ€å¾Œã® ] ã‚’æŠ½å‡º
    start = text.find("[")
    end = text.rfind("]")
    if start == -1 or end == -1:
        raise ValueError("JSONé…åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    json_text = text[start:end + 1]

    try:
        return json.loads(json_text)
    except json.JSONDecodeError as e:
        raise ValueError(
            f"JSONè§£æå¤±æ•—: {e}\n\n--- Geminiå‡ºåŠ› ---\n{text}"
        )

def generate_ai_problems(text, n=5):
    model = genai.GenerativeModel("gemini-flash-latest")

    system_prompt = """
ã‚ãªãŸã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“å¯¾ç­–å•é¡Œã‚’ä½œæˆã™ã‚‹æ•™è‚²AIã§ã™ã€‚

ã€å³å®ˆäº‹é …ã€‘
ãƒ»æä¾›è³‡æ–™ã®å†…å®¹ã®ã¿ã‹ã‚‰ä½œå•ã™ã‚‹
ãƒ»è–¬å‰¤å¸«å›½å®¶è©¦é¨“å½¢å¼ï¼ˆ5æŠå˜ä¸€é¸æŠï¼‰ã¨ã™ã‚‹
ãƒ»æ­£è§£ã¯å¿…ãš1ã¤
ãƒ»èª¤ã‚Šã®é¸æŠè‚¢ã¯çŸ¥è­˜ä¸è¶³ã§é¸ã³ã‚„ã™ã„ã‚‚ã®ã«ã™ã‚‹
ãƒ»JSONã®ã¿å‡ºåŠ›
ãƒ»JSONã®ã‚­ãƒ¼ã‚„å€¤ã«æ”¹è¡Œã‚’å«ã‚ãªã„
ãƒ»choicesã®å„é¸æŠè‚¢ã¯1æ–‡ã§å®Œçµã•ã›ã‚‹
ãƒ»èª¬æ˜æ–‡ã¯100æ–‡å­—ä»¥å†…
ãƒ»æ•°å¼ã¯ LaTeX ã‚„ $ è¨˜æ³•ã‚’ä½¿ã‚ãšã€ã™ã¹ã¦æ–‡ç« ã¾ãŸã¯é€šå¸¸ã®è¨˜å·ã§æ›¸ã
ãƒ»ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆ\ï¼‰ã‚’ä¸€åˆ‡ä½¿ç”¨ã—ãªã„
"""

    prompt = f"""
ä»¥ä¸‹ã®è³‡æ–™ã‹ã‚‰ {n} å•ã®äº”è‚¢æŠä¸€å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
ãƒ»å„å•é¡Œã«å¿…ãšã€Œtopicï¼ˆåˆ†é‡åï¼‰ã€ã‚’ä»˜ã‘ã‚‹
ãƒ»topicã¯è–¬å‰¤å¸«å›½å®¶è©¦é¨“ã®ç§‘ç›®ãƒ»é ˜åŸŸåã§ç°¡æ½”ã«æ›¸ã
  ï¼ˆä¾‹ï¼šè–¬ç‰©å‹•æ…‹å­¦ã€è£½å‰¤å­¦ã€ç‰©ç†è–¬å‰¤å­¦ã€è–¬ç†å­¦ ãªã©ï¼‰

å‡ºåŠ›å½¢å¼:
[
  {{
    "topic": "...",
    "question": "...",
    "choices": {{
      "A": "...",
      "B": "...",
      "C": "...",
      "D": "...",
      "E": "..."
    }},
    "correct": "A",
    "explanation": "..."
  }}
]

è³‡æ–™:
{text[:3000]}
"""

    response = model.generate_content(
        [system_prompt, prompt],
        generation_config={"temperature": 0.2,"response_mime_type": "application/json"}
    )

    return safe_json_load(response.text)


def get_ai_coaching_message(df):
    if df.empty:
        return "ã¾ã å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    # åˆ†é‡åˆ¥çµ±è¨ˆ
    stats = df.groupby("topic").agg(
        æ­£è§£æ•°=("is_correct", "sum"),
        å›ç­”æ•°=("id", "count")
    )
    stats["æ­£ç­”ç‡"] = stats["æ­£è§£æ•°"] / stats["å›ç­”æ•°"]
    stats_csv = stats.sort_values("æ­£ç­”ç‡").to_csv()

    model = genai.GenerativeModel("gemini-flash-latest")

    prompt = f"""
ã‚ãªãŸã¯ã€è–¬å­¦æ•™è‚²ãƒ»å›½å®¶è©¦é¨“æŒ‡å°ã‚’å°‚é–€ã¨ã™ã‚‹å¤§å­¦æ•™å“¡ã€‘ã§ã™ã€‚ä»¥ä¸‹ã¯ã€ã‚ã‚‹å­¦ç”Ÿã®æ¼”ç¿’çµæœï¼ˆåˆ†é‡åˆ¥ï¼‰ã§ã™ã€‚
ã€åˆ†é‡åˆ¥æˆç¸¾ã€‘
{stats_csv}
ã“ã®çµæœã‹ã‚‰ã€
â‘  å­¦å•çš„ã«ç†è§£ãŒä¸ååˆ†ã¨è€ƒãˆã‚‰ã‚Œã‚‹æ¦‚å¿µ
â‘¡ å­¦ç”ŸãŒé™¥ã‚Šã‚„ã™ã„èª¤è§£ã®å†…å®¹
â‘¢ ãã‚Œã‚’å…‹æœã™ã‚‹ãŸã‚ã®å…·ä½“çš„å­¦ç¿’æ–¹æ³•
ã‚’ãã‚Œãã‚Œæ˜ç¢ºã«æ›¸ã„ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
ãƒ»å‰ç½®ãã‚„æŒ¨æ‹¶æ–‡ã¯ç¦æ­¢
ãƒ»ã™ãã«åˆ†æã‹ã‚‰æ›¸ãå§‹ã‚ã‚‹
"""

    try:
        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.2,
                "max_output_tokens": 1000
            }
        )
        return response.text

    except Exception as e:
        return f"âŒ AIã‚³ãƒ¼ãƒãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"


# =====================================================
# UI
# =====================================================

def main():
    st.set_page_config("AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª", layout="centered")
    st.title("ğŸ“š AIã‚³ãƒ¼ãƒãƒ³ã‚°å­¦ç¿’ã‚¢ãƒ—ãƒª")

    init_db()
    if not configure_gemini():
        return

    if "text" not in st.session_state:
        st.session_state.text = None
    if "problems" not in st.session_state:
        st.session_state.problems = []
    if "idx" not in st.session_state:
        st.session_state.idx = 0
    if "answered" not in st.session_state:
        st.session_state.answered = False

    tab1, tab2, tab3 = st.tabs(["è³‡æ–™", "å•é¡Œæ¼”ç¿’", "ã‚³ãƒ¼ãƒãƒ³ã‚°"])

    # ---------- è³‡æ–™ ----------
    with tab1:
        file = st.file_uploader(
            "è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "pptx"]
        )
        if file:
            with st.spinner("è³‡æ–™è§£æä¸­..."):
                st.session_state.text = extract_text(file)
            st.success("è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            if st.button("AIå•é¡Œã‚’ç”Ÿæˆ"):
                try:
                    st.session_state.problems = generate_ai_problems(
                        st.session_state.text
                    )
                    st.session_state.idx = 0
                    st.success("å•é¡Œã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                    st.rerun()

                except Exception as e:
                    st.error("âŒ å•é¡Œç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    st.exception(e)

    # ---------- å•é¡Œ ----------
    with tab2:
        if not st.session_state.problems:
            st.info("å•é¡ŒãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
            return

    # --- å…¨å•çµ‚äº† ---
        if st.session_state.idx >= len(st.session_state.problems):
            st.success("ğŸ‰ ã™ã¹ã¦ã®å•é¡ŒãŒçµ‚äº†ã—ã¾ã—ãŸï¼")

            df = get_stats()
            correct = df["is_correct"].sum() if not df.empty else 0
            st.write(f"æ­£è§£æ•°: {correct} / {len(st.session_state.problems)}")

            if st.button("ã‚‚ã†ä¸€åº¦æœ€åˆã‹ã‚‰"):
                st.session_state.idx = 0
                st.session_state.answered = False
                st.rerun()
            return

        p = st.session_state.problems[st.session_state.idx]
        st.subheader(f"å•é¡Œ {st.session_state.idx + 1}")
        st.markdown(p["question"])

        choice = st.radio(
            "é¸æŠè‚¢",
            options=list(p["choices"].keys()),
            format_func=lambda x: f"{x}: {p['choices'][x]}",
            key=f"choice_{st.session_state.idx}"
        )

        # --- è§£ç­”ã™ã‚‹ ---
        if not st.session_state.answered:
            if st.button("è§£ç­”ã™ã‚‹"):
                st.session_state.answered = True
                st.session_state.is_correct = (choice == p["correct"])
                topic = p.get("topic", "æœªåˆ†é¡")
                log_result(topic, st.session_state.is_correct)



        # --- è§£ç­”å¾Œè¡¨ç¤º ---
        if st.session_state.answered:
            if st.session_state.is_correct:
                st.success("æ­£è§£ã§ã™ ğŸ‰")
            else:
                st.error(f"ä¸æ­£è§£ã§ã™ã€‚æ­£è§£ã¯ {p['correct']} ã§ã™ã€‚")

            st.markdown("### è§£èª¬")
            st.markdown(p["explanation"])

            # --- æ¬¡ã®å•é¡Œã¸ ---
            if st.button("æ¬¡ã®å•é¡Œã¸"):
                st.session_state.idx += 1
                st.session_state.answered = False
                st.rerun()






    # ---------- ã‚³ãƒ¼ãƒãƒ³ã‚° ----------
    with tab3:
        df = get_stats()
        if df.empty:
            st.info("å­¦ç¿’å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.subheader("åˆ†é‡åˆ¥ æ­£ç­”ç‡")
            stats = df.groupby("topic").agg(
                æ­£è§£æ•°=("is_correct", "sum"),
                å›ç­”æ•°=("id", "count")
            )
            stats["æ­£ç­”ç‡"] = stats["æ­£è§£æ•°"] / stats["å›ç­”æ•°"]
            st.dataframe(stats, width="stretch")

            if st.button("AIã‚³ãƒ¼ãƒãƒ³ã‚°ã‚’æ›´æ–°"):
                with st.spinner("åˆ†æä¸­..."):
                    msg = get_ai_coaching_message(df)
                st.info(msg)


if __name__ == "__main__":
    main()































